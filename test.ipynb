{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/04\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepdata\n"
     ]
    }
   ],
   "source": [
    "print(\"prepdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder_int(object):\n",
    "    \"\"\"One hot encoder for integer inputs with overflows\n",
    "    \n",
    "    Arguments:\n",
    "        object {[type]} -- [description]\n",
    "    \"\"\"\n",
    "    def __init__(self, categorical_features, lowerlimit=None, upperlimit=None):\n",
    "        self.iscategorical = categorical_features\n",
    "        self.ncolumns = len(categorical_features)\n",
    "        self.ncats=0\n",
    "        self.categories_per_feature = []\n",
    "\n",
    "        self.ncatgroups = 0\n",
    "        for b in categorical_features:\n",
    "            if b:\n",
    "                self.ncatgroups += 1\n",
    "        self.lowerlimit = lowerlimit # initial set to the input, but will be checked later\n",
    "        self.upperlimit = upperlimit # initial set to the input, but will be checked later\n",
    "        self.categories_fixed = False\n",
    "        pass\n",
    "\n",
    "    def applylimit(self, categoricalinputdata):\n",
    "        # should check whether lower limit set makes sense\n",
    "        if self.lowerlimit is None:\n",
    "            self.lowerlimit = np.min(categoricalinputdata, axis=0)\n",
    "        else:\n",
    "            self.lowerlimit = np.maximum(self.lowerlimit, np.min(categoricalinputdata, axis=0))\n",
    "        \n",
    "        # should check whether upper limit set makes sense\n",
    "        if self.upperlimit is None:\n",
    "            self.upperlimit = np.max(categoricalinputdata, axis=0)\n",
    "        else:\n",
    "            self.upperlimit = np.minimum(self.upperlimit, np.max(categoricalinputdata, axis=0))\n",
    "\n",
    "        lowerlimitapp = np.maximum(categoricalinputdata, self.lowerlimit)\n",
    "        #limitapp = np.minimum(lowerlimitapp, self.upperlimit).astype(int)\n",
    "        limitapp = np.minimum(lowerlimitapp, self.upperlimit)\n",
    "        return limitapp\n",
    "\n",
    "    def _encode(self, inputdata):\n",
    "        categorical_columns=inputdata[:, self.iscategorical]\n",
    "        float_columns=inputdata[:, [not i for i in self.iscategorical]]\n",
    "\n",
    "        cat_limited = self.applylimit(categorical_columns)-self.lowerlimit.astype(int)\n",
    "\n",
    "        catshape = categorical_columns.shape\n",
    "\n",
    "        arraylist=[]\n",
    "        if not self.categories_fixed:\n",
    "            for cat in range(catshape[1]):\n",
    "                ncats = int(self.upperlimit[cat] - self.lowerlimit[cat] + 1) # number of categories\n",
    "                self.categories_per_feature.append(ncats)\n",
    "                self.ncats += ncats\n",
    "            self.categories_fixed = True\n",
    "\n",
    "        for cat in range(catshape[1]):\n",
    "            ncats = int(self.upperlimit[cat] - self.lowerlimit[cat] + 1) # number of categories\n",
    "            res = np.eye(ncats)[cat_limited[:,cat]]\n",
    "            #print(res)\n",
    "            arraylist.append(res)\n",
    "        if float_columns.shape[1]>0:\n",
    "            arraylist.append(float_columns)\n",
    "        encoded = np.concatenate(tuple(arraylist), axis=1).astype(np.float32)\n",
    "        return encoded\n",
    "\n",
    "    def encode(self, inputdata):\n",
    "\n",
    "        cat_limited = self.applylimit(inputdata)-self.lowerlimit\n",
    "        #print(self.applylimit(inputdata))\n",
    "        #print(self.lowerlimit)\n",
    "        #print(cat_limited)\n",
    "\n",
    "        # one hot encoding information\n",
    "        if not self.categories_fixed:\n",
    "            for icol, iscat in zip(range(self.ncolumns), self.iscategorical):\n",
    "                if iscat:\n",
    "                    ncats = int(self.upperlimit[icol] - self.lowerlimit[icol] + 1) # number of categories\n",
    "                    self.categories_per_feature.append(ncats)\n",
    "                    self.ncats += ncats\n",
    "                else:\n",
    "                    self.categories_per_feature.append(0)\n",
    "            self.categories_fixed = True\n",
    "\n",
    "        # the actual encoding part\n",
    "        arraylist=[]\n",
    "        for icol, ncat_feat in zip(range(self.ncolumns), self.categories_per_feature):\n",
    "            if ncat_feat>0:\n",
    "                res = np.eye(ncat_feat)[cat_limited[:,icol].astype(int)]\n",
    "                arraylist.append(res)\n",
    "            else:\n",
    "                arraylist.append(inputdata[:,icol].reshape((inputdata.shape[0], 1)))\n",
    "\n",
    "        encoded = np.concatenate(tuple(arraylist), axis=1).astype(np.float32)\n",
    "        return encoded\n",
    "    \n",
    "    def encodedcategories(self):\n",
    "        return self.ncats\n",
    "\n",
    "    def transform(self, inputdata):\n",
    "        return self.encode(inputdata)\n",
    "\n",
    "    def _decode(self, onehotdata):\n",
    "        colstart = 0\n",
    "        \n",
    "        arraylist = []\n",
    "        for i in range(self.ncatgroups):\n",
    "            ncats = int(self.upperlimit[i] - self.lowerlimit[i]+1)  # number of categories\n",
    "            datatoconvert = onehotdata[:, colstart:colstart+ncats]\n",
    "            converted = np.argmax(datatoconvert, axis=1) + self.lowerlimit[i]\n",
    "            converted = np.reshape(converted, newshape=(converted.shape[0], 1))\n",
    "            arraylist.append(converted)\n",
    "            colstart += ncats\n",
    "        if colstart<onehotdata.shape[1]:\n",
    "            arraylist.append(onehotdata[:, colstart:])\n",
    "        decoded = np.concatenate(tuple(arraylist), axis=1)\n",
    "        return decoded\n",
    "\n",
    "    def decode(self, onehotdata):\n",
    "        current_col = 0 # start from column 0\n",
    "        arraylist = []\n",
    "        for ifeat, ncats in zip(range(len(self.categories_per_feature)), self.categories_per_feature):\n",
    "            if ncats>0:\n",
    "                datatoconvert = onehotdata[:, current_col:current_col+ncats]\n",
    "                converted = np.argmax(datatoconvert, axis=1) + self.lowerlimit[ifeat]\n",
    "                converted = np.reshape(converted, newshape=(converted.shape[0], 1))\n",
    "                arraylist.append(converted)\n",
    "                current_col += ncats\n",
    "            else:\n",
    "                arraylist.append(onehotdata[:, current_col].reshape((onehotdata.shape[0], 1)))\n",
    "                current_col += 1\n",
    "        decoded = np.concatenate(tuple(arraylist), axis=1)\n",
    "        return decoded\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 8 10  8]]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  4.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  7.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1. 10.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 2.  1.  2.]\n",
      " [ 3.  4.  5.]\n",
      " [ 6.  7.  8.]\n",
      " [ 8. 10.  8.]]\n",
      "\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  4.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  7.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1. 10.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.]]\n",
      "[[ 0.  1.  2.]\n",
      " [ 3.  4.  5.]\n",
      " [ 6.  7.  8.]\n",
      " [ 9. 10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[ 0,  1,  2], [ 3,  4,  5], [ 6,  7,  8], [ 9, 10, 11]])\n",
    "ohe = OneHotEncoder_int(categorical_features=[True, False, True], lowerlimit=[2,0,2], upperlimit=[8,100,8])\n",
    "xlimited = ohe.applylimit(x)\n",
    "print(xlimited)\n",
    "encodedx = ohe.encode(x)\n",
    "print(encodedx)\n",
    "decoded = ohe.decode(encodedx)\n",
    "print(decoded)\n",
    "print()\n",
    "ohe2 = OneHotEncoder_int(categorical_features=[True, False, True])\n",
    "xlimited = ohe2.applylimit(x)\n",
    "print(xlimited)\n",
    "encodedx = ohe2.encode(x)\n",
    "print(encodedx)\n",
    "decoded = ohe2.decode(encodedx)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurevars = ['met', 'ht', 'pt5', 'pt6', 'njet', 'nbtag']\n",
    "\n",
    "rootfile='ttjjresult.root'\n",
    "\n",
    "ttjj = uproot.open(rootfile)\n",
    "ttjjtree = ttjj['mytree']\n",
    "iscategorical = [False, False, False, False, True, True]\n",
    "upperlimit = [10, 10, 10, 10, 9, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputtmp = ttjjtree.df(featurevars)\n",
    "arrays = ttjjtree.arrays(featurevars, library=\"pd\")\n",
    "inputtmp = pd.DataFrame(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_onehotencoder = OneHotEncoder_int(iscategorical, upperlimit=upperlimit)\n",
    "iscategorical = np.array(inputtmp.dtypes == np.int32)\n",
    "\n",
    "inputnumpy = inputtmp.to_numpy(dtype=np.float32)\n",
    "inputs = _onehotencoder.encode(inputnumpy)\n",
    "ncats = _onehotencoder.ncats\n",
    "ncat_per_feature = _onehotencoder.categories_per_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  84.002205  765.41595    96.49143    83.413086    7.          2.      ]\n",
      " [  95.23368   924.5049     71.028915   68.11747    11.          2.      ]\n",
      " [  54.86022  1668.8479     76.10241    46.142303   10.          3.      ]\n",
      " ...\n",
      " [   8.826685  555.999      38.395134   34.18226     9.          2.      ]\n",
      " [  41.213657  687.2156     58.986603   51.859745    9.          2.      ]\n",
      " [  56.09024   498.0826     51.162266   47.752556    8.          2.      ]]\n",
      "[[8.4002205e+01 7.6541595e+02 9.6491432e+01 ... 0.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00]\n",
      " [9.5233681e+01 9.2450488e+02 7.1028915e+01 ... 1.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00]\n",
      " [5.4860222e+01 1.6688479e+03 7.6102409e+01 ... 1.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00]\n",
      " ...\n",
      " [8.8266850e+00 5.5599902e+02 3.8395134e+01 ... 1.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00]\n",
      " [4.1213657e+01 6.8721558e+02 5.8986603e+01 ... 1.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00]\n",
      " [5.6090240e+01 4.9808261e+02 5.1162266e+01 ... 0.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00]]\n",
      "5\n",
      "[0, 0, 0, 0, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(inputnumpy)\n",
    "print(inputs)\n",
    "print(ncats)\n",
    "print(ncat_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52.657894 698.1734    58.784267  46.991592   0.         0.\n",
      "    0.         0.         0.      ]]\n",
      "[array([[52.657894]], dtype=float32), array([[698.1734]], dtype=float32), array([[58.784267]], dtype=float32), array([[46.991592]], dtype=float32), array([[0., 0., 0.]], dtype=float32), array([[0., 0.]], dtype=float32)] [array([[47.973377]], dtype=float32), array([[267.8131]], dtype=float32), array([[22.807163]], dtype=float32), array([[17.591656]], dtype=float32), array([[1., 1., 1.]], dtype=float32), array([[1., 1.]], dtype=float32)]\n",
      "[[ 0.65336883  0.25108016  1.6533036  ...  0.          1.\n",
      "   0.        ]\n",
      " [ 0.88748777  0.8451098   0.5368773  ...  1.          1.\n",
      "   0.        ]\n",
      " [ 0.04590729  3.6244473   0.7593291  ...  1.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.9136569  -0.5308716  -0.8939794  ...  1.          1.\n",
      "   0.        ]\n",
      " [-0.23855391 -0.04091594  0.00887157 ...  1.          1.\n",
      "   0.        ]\n",
      " [ 0.0715469  -0.7471284  -0.33419332 ...  0.          1.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "meanslist = []\n",
    "sigmalist = []\n",
    "currentcolumn = 0\n",
    "for ifeat, ncatfeat in zip(range(inputtmp.shape[1]), ncat_per_feature):\n",
    "    if ncatfeat == 0: # fir float features, get mean and sigma\n",
    "        mean = np.mean(inputnumpy[:, currentcolumn], axis=0, dtype=np.float32).reshape(1,1)\n",
    "        meanslist.append(mean)\n",
    "        sigma = np.std(inputnumpy[:, currentcolumn], axis=0, dtype=np.float32).reshape(1,1)\n",
    "        sigmalist.append(sigma)\n",
    "        currentcolumn += 1\n",
    "    else: # categorical features do not get changed\n",
    "        mean = np.zeros(shape=(1, ncatfeat), dtype=np.float32) \n",
    "        meanslist.append(mean)\n",
    "        sigma = np.ones(shape=(1, ncatfeat), dtype=np.float32)\n",
    "        sigmalist.append(sigma)\n",
    "        currentcolumn += ncatfeat\n",
    "\n",
    "inputmeans = np.hstack(meanslist)\n",
    "inputsigma = np.hstack(sigmalist)\n",
    "\n",
    "normedinputs = (inputs-inputmeans) / inputsigma\n",
    "\n",
    "print(inputmeans)\n",
    "print(meanslist, sigmalist)\n",
    "print(normedinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normedinputs.shape[1] - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9)\n",
      "[4 9 2 6 7 0 3 8 5 1]\n",
      "[2 3 1 0]\n"
     ]
    }
   ],
   "source": [
    "a = inputs[0:10]\n",
    "print(a.shape)\n",
    "\n",
    "b = np.random.permutation(a.shape[0])\n",
    "print(b)\n",
    "nextconditional = a[b[2],4:]\n",
    "print(np.random.permutation(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 84.002205  95.23368   54.86022   37.8228    29.449005  57.611637\n",
      "  40.065826  62.580334  59.275562 133.99251 ]\n",
      "[[8.4002205e+01 7.6541595e+02 9.6491432e+01 8.3413086e+01 1.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [9.5233681e+01 9.2450488e+02 7.1028915e+01 6.8117470e+01 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [5.4860222e+01 1.6688479e+03 7.6102409e+01 4.6142303e+01 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [3.7822800e+01 3.5504123e+02 3.8004093e+01 3.6965599e+01 0.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [2.9449005e+01 5.5566846e+02 6.2723263e+01 4.5919170e+01 1.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [5.7611637e+01 4.8155209e+02 5.8068291e+01 4.3973988e+01 0.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [4.0065826e+01 9.4344019e+02 9.5859024e+01 9.1362709e+01 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [6.2580334e+01 3.9724319e+02 4.4696854e+01 4.3293205e+01 0.0000000e+00\n",
      "  1.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [5.9275562e+01 1.0228308e+03 8.2236763e+01 6.5931435e+01 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      " [1.3399251e+02 5.2389960e+02 5.1825226e+01 5.0228535e+01 1.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 84.002205],\n",
       "       [ 95.23368 ],\n",
       "       [ 54.86022 ],\n",
       "       [ 37.8228  ],\n",
       "       [ 29.449005],\n",
       "       [ 57.611637],\n",
       "       [ 40.065826],\n",
       "       [ 62.580334],\n",
       "       [ 59.275562],\n",
       "       [133.99251 ]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a[:,0])\n",
    "print(a)\n",
    "tf.reshape(a[:,0],[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 84.002205]\n",
      " [ 95.23368 ]\n",
      " [ 54.86022 ]\n",
      " [ 37.8228  ]\n",
      " [ 29.449005]\n",
      " [ 57.611637]\n",
      " [ 40.065826]\n",
      " [ 62.580334]\n",
      " [ 59.275562]\n",
      " [133.99251 ]], shape=(10, 1), dtype=float32)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), name='dense_109/Softplus:0', description=\"created by layer 'dense_109'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), name='dense_110/BiasAdd:0', description=\"created by layer 'dense_110'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 16), dtype=tf.float32, name=None), name='tf.math.sigmoid_15/Sigmoid:0', description=\"created by layer 'tf.math.sigmoid_15'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 16), dtype=tf.float32, name=None), name='tf.math.truediv_29/truediv:0', description=\"created by layer 'tf.math.truediv_29'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 1), dtype=tf.float32, name=None), name='tf.math.log_14/Log:0', description=\"created by layer 'tf.math.log_14'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), name='tf.__operators__.getitem_14/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_14'\") tf.Tensor(\n",
      "[[ 84.002205]\n",
      " [ 95.23368 ]\n",
      " [ 54.86022 ]\n",
      " [ 37.8228  ]\n",
      " [ 29.449005]\n",
      " [ 57.611637]\n",
      " [ 40.065826]\n",
      " [ 62.580334]\n",
      " [ 59.275562]\n",
      " [133.99251 ]], shape=(10, 1), dtype=float32)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 6), dtype=tf.float32, name=None), name='tf.concat_14/concat:0', description=\"created by layer 'tf.concat_14'\")\n",
      "tf.Tensor(\n",
      "[[ 765.41595]\n",
      " [ 924.5049 ]\n",
      " [1668.8479 ]\n",
      " [ 355.04123]\n",
      " [ 555.66846]\n",
      " [ 481.5521 ]\n",
      " [ 943.4402 ]\n",
      " [ 397.2432 ]\n",
      " [1022.8308 ]\n",
      " [ 523.8996 ]], shape=(10, 1), dtype=float32)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 16), dtype=tf.float32, name=None), name='dense_116/Softplus:0', description=\"created by layer 'dense_116'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 16), dtype=tf.float32, name=None), name='dense_117/BiasAdd:0', description=\"created by layer 'dense_117'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 16), dtype=tf.float32, name=None), name='tf.math.sigmoid_16/Sigmoid:0', description=\"created by layer 'tf.math.sigmoid_16'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 16), dtype=tf.float32, name=None), name='tf.math.truediv_31/truediv:0', description=\"created by layer 'tf.math.truediv_31'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 1), dtype=tf.float32, name=None), name='tf.math.log_15/Log:0', description=\"created by layer 'tf.math.log_15'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 6), dtype=tf.float32, name=None), name='tf.concat_14/concat:0', description=\"created by layer 'tf.concat_14'\") tf.Tensor(\n",
      "[[ 765.41595]\n",
      " [ 924.5049 ]\n",
      " [1668.8479 ]\n",
      " [ 355.04123]\n",
      " [ 555.66846]\n",
      " [ 481.5521 ]\n",
      " [ 943.4402 ]\n",
      " [ 397.2432 ]\n",
      " [1022.8308 ]\n",
      " [ 523.8996 ]], shape=(10, 1), dtype=float32)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(10, 7), dtype=tf.float32, name=None), name='tf.concat_15/concat:0', description=\"created by layer 'tf.concat_15'\")\n"
     ]
    }
   ],
   "source": [
    "def invsigmoid(x):\n",
    "    xclip = tf.clip_by_value(x, 1e-6, 1.0-1e-6)\n",
    "    #xclip = x\n",
    "    return tf.math.log(xclip/(1.0-xclip))\n",
    "\n",
    "xin = tf.keras.layers.Input(shape=(4+5, ))\n",
    "xcondin = xin[:, 4:]\n",
    "outlist = []\n",
    "\n",
    "tfk = tf.keras\n",
    "nafdim = 16\n",
    "\n",
    "for iv in range(2):\n",
    "    xiv = tf.reshape(a[:,iv],[-1,1])\n",
    "    net = xiv\n",
    "    condnet = xcondin\n",
    "\n",
    "    print(net)\n",
    "\n",
    "    condnet = tfk.layers.Dense(128, activation=tf.nn.swish)(condnet)\n",
    "    condnet = tfk.layers.Dense(128, activation=tf.nn.swish)(condnet)\n",
    "    w1 = tfk.layers.Dense(nafdim, activation=tf.nn.softplus)(condnet)\n",
    "    b1 = tfk.layers.Dense(nafdim, activation=None)(condnet)\n",
    "\n",
    "    net1 = tf.nn.sigmoid(w1 * net + b1)\n",
    "    print(w1)\n",
    "    print(b1)\n",
    "    print(net1)\n",
    "    condnet = xcondin\n",
    "    condnet = tfk.layers.Dense(128, activation=tf.nn.swish)(condnet)\n",
    "    condnet = tfk.layers.Dense(128, activation=tf.nn.swish)(condnet)\n",
    "    w2 = tfk.layers.Dense(nafdim, activation=tf.nn.softplus)(condnet)\n",
    "    w2 = w2/ (1.0e-3 + tf.reduce_sum(w2, axis=1,keepdims=True)) # normalize\n",
    "\n",
    "    net = invsigmoid(tf.reduce_sum(net1 * w2, axis=1, keepdims=True))\n",
    "    print(w2)\n",
    "    print(net)\n",
    "    outlist.append(net)\n",
    "    print(xcondin,xiv)\n",
    "    xcondin = tf.concat([xcondin, xiv], axis=1)\n",
    "    print(xcondin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(10, 2), dtype=tf.float32, name=None), name='tf.concat_16/concat:0', description=\"created by layer 'tf.concat_16'\")\n"
     ]
    }
   ],
   "source": [
    "outputlayer_permuted = tf.concat(outlist, axis=1)\n",
    "print(outputlayer_permuted)\n",
    "#outputlayer = permuter.inverse(outputlayer_permuted)\n",
    "#nextfeature = outputlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.40022049e+01, 7.65415955e+02, 9.64914322e+01, 8.34130859e+01,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [9.52336807e+01, 9.24504883e+02, 7.10289154e+01, 6.81174698e+01,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00],\n",
       "       [5.48602219e+01, 1.66884790e+03, 7.61024094e+01, 4.61423035e+01,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = [[1., 0., 0.,   1., 0., ]]\n",
    "minibatch = 3\n",
    "cond_to_append = np.repeat(cond, minibatch, axis=0)\n",
    "print(cond_to_append)\n",
    "xin = a[0:3,:4]\n",
    "np.hstack((xin, cond_to_append))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
